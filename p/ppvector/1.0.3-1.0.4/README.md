# Comparing `tmp/ppvector-1.0.3-py3-none-any.whl.zip` & `tmp/ppvector-1.0.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,35 +1,35 @@
-Zip file size: 64337 bytes, number of entries: 33
--rw-rw-rw-  2.0 fat      134 b- defN 24-May-03 03:43 ppvector/__init__.py
--rw-rw-rw-  2.0 fat    17483 b- defN 24-May-02 09:44 ppvector/predict.py
--rw-rw-rw-  2.0 fat    36494 b- defN 24-May-02 12:43 ppvector/trainer.py
+Zip file size: 64822 bytes, number of entries: 33
+-rw-rw-rw-  2.0 fat      148 b- defN 24-May-04 06:51 ppvector/__init__.py
+-rw-rw-rw-  2.0 fat    17667 b- defN 24-May-03 14:30 ppvector/predict.py
+-rw-rw-rw-  2.0 fat    37307 b- defN 24-May-04 06:43 ppvector/trainer.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Nov-04 14:44 ppvector/data_utils/__init__.py
 -rw-rw-rw-  2.0 fat    22221 b- defN 24-Apr-27 05:31 ppvector/data_utils/audio.py
 -rw-rw-rw-  2.0 fat      947 b- defN 24-May-02 09:35 ppvector/data_utils/collate_fn.py
 -rw-rw-rw-  2.0 fat     3919 b- defN 24-May-02 09:36 ppvector/data_utils/featurizer.py
 -rw-rw-rw-  2.0 fat     7419 b- defN 24-May-02 09:47 ppvector/data_utils/reader.py
 -rw-rw-rw-  2.0 fat     1581 b- defN 23-Aug-29 13:07 ppvector/data_utils/spec_aug.py
 -rw-rw-rw-  2.0 fat     4713 b- defN 24-Jan-06 11:55 ppvector/data_utils/utils.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-16 05:03 ppvector/metric/__init__.py
 -rw-rw-rw-  2.0 fat     1208 b- defN 23-Aug-29 13:07 ppvector/metric/metrics.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Nov-05 11:08 ppvector/models/__init__.py
 -rw-rw-rw-  2.0 fat    12745 b- defN 23-Aug-29 13:07 ppvector/models/campplus.py
 -rw-rw-rw-  2.0 fat    10987 b- defN 24-May-02 09:33 ppvector/models/ecapa_tdnn.py
--rw-rw-rw-  2.0 fat    10135 b- defN 23-Aug-29 13:07 ppvector/models/eres2net.py
+-rw-rw-rw-  2.0 fat    17612 b- defN 24-May-03 14:47 ppvector/models/eres2net.py
 -rw-rw-rw-  2.0 fat     3731 b- defN 24-Jan-10 12:55 ppvector/models/fc.py
 -rw-rw-rw-  2.0 fat     9521 b- defN 24-Jan-10 12:55 ppvector/models/loss.py
--rw-rw-rw-  2.0 fat     5279 b- defN 23-Aug-29 13:07 ppvector/models/pooling.py
+-rw-rw-rw-  2.0 fat     5283 b- defN 24-May-03 14:30 ppvector/models/pooling.py
 -rw-rw-rw-  2.0 fat     6843 b- defN 23-Aug-29 13:07 ppvector/models/res2net.py
 -rw-rw-rw-  2.0 fat     5662 b- defN 23-Aug-29 13:07 ppvector/models/resnet_se.py
 -rw-rw-rw-  2.0 fat     3459 b- defN 23-Aug-29 13:07 ppvector/models/tdnn.py
 -rw-rw-rw-  2.0 fat     5049 b- defN 23-Aug-05 13:45 ppvector/models/utils.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Nov-04 14:44 ppvector/utils/__init__.py
 -rw-rw-rw-  2.0 fat     2839 b- defN 22-Nov-04 14:44 ppvector/utils/logger.py
 -rw-rw-rw-  2.0 fat     1385 b- defN 24-Jan-15 12:44 ppvector/utils/record.py
 -rw-rw-rw-  2.0 fat     3399 b- defN 24-Jan-17 14:13 ppvector/utils/scheduler.py
 -rw-rw-rw-  2.0 fat     2790 b- defN 23-Mar-16 11:21 ppvector/utils/utils.py
--rw-rw-rw-  2.0 fat    11558 b- defN 24-May-03 03:43 ppvector-1.0.3.dist-info/LICENSE
--rw-rw-rw-  2.0 fat    34237 b- defN 24-May-03 03:43 ppvector-1.0.3.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 24-May-03 03:43 ppvector-1.0.3.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        9 b- defN 24-May-03 03:43 ppvector-1.0.3.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     2709 b- defN 24-May-03 03:43 ppvector-1.0.3.dist-info/RECORD
-33 files, 228548 bytes uncompressed, 60021 bytes compressed:  73.7%
+-rw-rw-rw-  2.0 fat    11558 b- defN 24-May-04 07:05 ppvector-1.0.4.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat    34554 b- defN 24-May-04 07:05 ppvector-1.0.4.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 24-May-04 07:05 ppvector-1.0.4.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        9 b- defN 24-May-04 07:05 ppvector-1.0.4.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     2709 b- defN 24-May-04 07:05 ppvector-1.0.4.dist-info/RECORD
+33 files, 237357 bytes uncompressed, 60506 bytes compressed:  74.5%
```

## zipnote {}

```diff
@@ -78,23 +78,23 @@
 
 Filename: ppvector/utils/scheduler.py
 Comment: 
 
 Filename: ppvector/utils/utils.py
 Comment: 
 
-Filename: ppvector-1.0.3.dist-info/LICENSE
+Filename: ppvector-1.0.4.dist-info/LICENSE
 Comment: 
 
-Filename: ppvector-1.0.3.dist-info/METADATA
+Filename: ppvector-1.0.4.dist-info/METADATA
 Comment: 
 
-Filename: ppvector-1.0.3.dist-info/WHEEL
+Filename: ppvector-1.0.4.dist-info/WHEEL
 Comment: 
 
-Filename: ppvector-1.0.3.dist-info/top_level.txt
+Filename: ppvector-1.0.4.dist-info/top_level.txt
 Comment: 
 
-Filename: ppvector-1.0.3.dist-info/RECORD
+Filename: ppvector-1.0.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## ppvector/__init__.py

```diff
@@ -1,3 +1,3 @@
-__version__ = "1.0.3"
+__version__ = "1.0.4"
 # 项目支持的模型
-SUPPORT_MODEL = ['ERes2Net', 'CAMPPlus', 'EcapaTdnn', 'Res2Net', 'ResNetSE', 'TDNN']
+SUPPORT_MODEL = ['ERes2Net', 'ERes2NetV2', 'CAMPPlus', 'EcapaTdnn', 'Res2Net', 'ResNetSE', 'TDNN']
```

## ppvector/predict.py

```diff
@@ -11,15 +11,15 @@
 from tqdm import tqdm
 
 from ppvector import SUPPORT_MODEL
 from ppvector.data_utils.audio import AudioSegment
 from ppvector.data_utils.featurizer import AudioFeaturizer
 from ppvector.models.campplus import CAMPPlus
 from ppvector.models.ecapa_tdnn import EcapaTdnn
-from ppvector.models.eres2net import ERes2Net
+from ppvector.models.eres2net import ERes2Net, ERes2NetV2
 from ppvector.models.res2net import Res2Net
 from ppvector.models.resnet_se import ResNetSE
 from ppvector.models.tdnn import TDNN
 from ppvector.utils.logger import setup_logger
 from ppvector.utils.utils import dict_to_object, print_arguments
 
 logger = setup_logger(__name__)
@@ -60,14 +60,16 @@
                                                  method_args=self.configs.preprocess_conf.get('method_args', {}))
         # 创建模型
         if not os.path.exists(model_path):
             raise Exception("模型文件不存在，请检查{}是否存在！".format(model_path))
         # 获取模型
         if self.configs.use_model == 'ERes2Net':
             backbone = ERes2Net(input_size=self._audio_featurizer.feature_dim, **self.configs.model_conf.backbone)
+        elif self.configs.use_model == 'ERes2NetV2':
+            backbone = ERes2NetV2(input_size=self._audio_featurizer.feature_dim, **self.configs.model_conf.backbone)
         elif self.configs.use_model == 'CAMPPlus':
             backbone = CAMPPlus(input_size=self._audio_featurizer.feature_dim, **self.configs.model_conf.backbone)
         elif self.configs.use_model == 'EcapaTdnn':
             backbone = EcapaTdnn(input_size=self._audio_featurizer.feature_dim, **self.configs.model_conf.backbone)
         elif self.configs.use_model == 'Res2Net':
             backbone = Res2Net(input_size=self._audio_featurizer.feature_dim, **self.configs.model_conf.backbone)
         elif self.configs.use_model == 'ResNetSE':
```

## ppvector/trainer.py

```diff
@@ -22,15 +22,15 @@
 from ppvector.data_utils.collate_fn import collate_fn
 from ppvector.data_utils.featurizer import AudioFeaturizer
 from ppvector.data_utils.reader import PPVectorDataset
 from ppvector.data_utils.spec_aug import SpecAug
 from ppvector.metric.metrics import compute_fnr_fpr, compute_eer, compute_dcf
 from ppvector.models.campplus import CAMPPlus
 from ppvector.models.ecapa_tdnn import EcapaTdnn
-from ppvector.models.eres2net import ERes2Net
+from ppvector.models.eres2net import ERes2Net, ERes2NetV2
 from ppvector.models.fc import SpeakerIdentification
 from ppvector.models.loss import AAMLoss, AMLoss, ARMLoss, CELoss, SubCenterLoss, SphereFace2
 from ppvector.models.res2net import Res2Net
 from ppvector.models.resnet_se import ResNetSE
 from ppvector.models.tdnn import TDNN
 from ppvector.utils.logger import setup_logger
 from ppvector.utils.scheduler import cosine_decay_with_warmup, MarginScheduler
@@ -165,14 +165,16 @@
                     f.write(f'{save_path}\t{label}\n')
             logger.info(f'{data_list}列表中的数据已提取特征完成，新列表为：{save_data_list}')
 
     def __setup_model(self, input_size, is_train=False):
         # 获取模型
         if self.configs.use_model == 'ERes2Net':
             self.backbone = ERes2Net(input_size=input_size, **self.configs.model_conf.backbone)
+        elif self.configs.use_model == 'ERes2NetV2':
+            self.backbone = ERes2NetV2(input_size=input_size, **self.configs.model_conf.backbone)
         elif self.configs.use_model == 'CAMPPlus':
             self.backbone = CAMPPlus(input_size=input_size, **self.configs.model_conf.backbone)
         elif self.configs.use_model == 'EcapaTdnn':
             self.backbone = EcapaTdnn(input_size=input_size, **self.configs.model_conf.backbone)
         elif self.configs.use_model == 'Res2Net':
             self.backbone = Res2Net(input_size=input_size, **self.configs.model_conf.backbone)
         elif self.configs.use_model == 'ResNetSE':
@@ -290,15 +292,19 @@
                                       'last_model')
         if resume_model is not None or (os.path.exists(os.path.join(last_model_dir, 'model.pdparams'))
                                         and os.path.exists(os.path.join(last_model_dir, 'optimizer.pdopt'))):
             # 自动获取最新保存的模型
             if resume_model is None: resume_model = last_model_dir
             assert os.path.exists(os.path.join(resume_model, 'model.pdparams')), "模型参数文件不存在！"
             assert os.path.exists(os.path.join(resume_model, 'optimizer.pdopt')), "优化方法参数文件不存在！"
-            self.model.set_state_dict(paddle.load(os.path.join(resume_model, 'model.pdparams')))
+            missing_keys, unexpected_keys = self.model.set_state_dict(
+                paddle.load(os.path.join(resume_model, 'model.pdparams')))
+            if len(missing_keys) != 0 or len(unexpected_keys) != 0:
+                logger.warning(f'模型加载部分失败，请检查模型是否匹配，'
+                               f'missing_keys: {missing_keys}, unexpected_keys: {unexpected_keys}')
             self.optimizer.set_state_dict(paddle.load(os.path.join(resume_model, 'optimizer.pdopt')))
             # 自动混合精度参数
             if self.amp_scaler is not None and os.path.exists(os.path.join(resume_model, 'scaler.pdparams')):
                 self.amp_scaler.load_state_dict(paddle.load(os.path.join(resume_model, 'scaler.pdparams')))
             with open(os.path.join(resume_model, 'model.state'), 'r', encoding='utf-8') as f:
                 json_data = json.load(f)
                 last_epoch = json_data['last_epoch'] - 1
@@ -396,15 +402,15 @@
             train_times.append((time.time() - start) * 1000)
             self.train_step += 1
 
             # 多卡训练只使用一个进程打印
             if batch_id % self.configs.train_conf.log_interval == 0 and local_rank == 0:
                 # 计算每秒训练数据量
                 train_speed = self.configs.dataset_conf.dataLoader.batch_size / (
-                            sum(train_times) / len(train_times) / 1000)
+                        sum(train_times) / len(train_times) / 1000)
                 # 计算剩余时间
                 self.train_eta_sec = (sum(train_times) / len(train_times)) * (self.max_step - self.train_step) / 1000
                 eta_str = str(timedelta(seconds=int(self.train_eta_sec)))
                 self.train_loss = sum(loss_sum) / len(loss_sum)
                 self.train_acc = sum(accuracies) / len(accuracies)
                 margin_str = f'margin: {self.margin_scheduler.get_margin()}' if self.margin_scheduler else ''
                 logger.info(f'Train epoch: [{epoch_id}/{self.configs.train_conf.max_epoch}], '
@@ -522,36 +528,41 @@
         if self.model is None:
             self.__setup_model(input_size=self.audio_featurizer.feature_dim)
         if resume_model is not None:
             if os.path.isdir(resume_model):
                 resume_model = os.path.join(resume_model, 'model.pdparams')
             assert os.path.exists(resume_model), f"{resume_model} 模型不存在！"
             model_state_dict = paddle.load(resume_model)
-            self.model.set_state_dict(model_state_dict)
+            missing_keys, unexpected_keys = self.model.set_state_dict(model_state_dict)
+            if len(missing_keys) != 0 or len(unexpected_keys) != 0:
+                logger.warning(f'模型加载部分失败，请检查模型是否匹配，'
+                               f'missing_keys: {missing_keys}, unexpected_keys: {unexpected_keys}')
             logger.info(f'成功加载模型：{resume_model}')
         self.model.eval()
         if isinstance(self.model, paddle.DataParallel):
             eval_model = self.model._layers if len(self.model._layers) == 1 else self.model._layers[0]
         else:
             eval_model = self.model if len(self.model) == 1 else self.model[0]
 
         # 获取注册的声纹特征和标签
         enroll_features, enroll_labels = None, None
         with paddle.no_grad():
-            for batch_id, (audio_features, label, input_lens) in enumerate(tqdm(self.enroll_loader, desc="注册音频声纹特征")):
+            for batch_id, (audio_features, label, input_lens) in enumerate(
+                    tqdm(self.enroll_loader, desc="注册音频声纹特征")):
                 if self.stop_eval: break
                 feature = eval_model(audio_features).numpy()
                 label = label.numpy()
                 # 存放特征
                 enroll_features = np.concatenate((enroll_features, feature)) if enroll_features is not None else feature
                 enroll_labels = np.concatenate((enroll_labels, label)) if enroll_labels is not None else label
         # 获取检验的声纹特征和标签
         trials_features, trials_labels = None, None
         with paddle.no_grad():
-            for batch_id, (audio_features, label, input_lens) in enumerate(tqdm(self.trials_loader, desc="验证音频声纹特征")):
+            for batch_id, (audio_features, label, input_lens) in enumerate(
+                    tqdm(self.trials_loader, desc="验证音频声纹特征")):
                 if self.stop_eval: break
                 feature = eval_model(audio_features).numpy()
                 label = label.numpy()
                 # 存放特征
                 trials_features = np.concatenate((trials_features, feature)) if trials_features is not None else feature
                 trials_labels = np.concatenate((trials_labels, label)) if trials_labels is not None else label
         self.model.train()
```

## ppvector/models/eres2net.py

```diff
@@ -2,14 +2,16 @@
 
 import paddle
 import paddle.nn as nn
 import paddle.nn.functional as F
 
 from ppvector.models.pooling import TemporalStatsPool
 
+__all__ = ['ERes2Net', 'ERes2NetV2']
+
 
 class ReLU(nn.Hardtanh):
 
     def __init__(self, inplace=False):
         super(ReLU, self).__init__(0, 20, inplace)
 
     def __repr__(self):
@@ -77,32 +79,29 @@
                 nn.Conv2D(in_planes, self.expansion * planes, kernel_size=1, stride=stride),
                 nn.BatchNorm2D(self.expansion * planes))
         self.stride = stride
         self.width = width
         self.scale = scale
 
     def forward(self, x):
-        residual = x
-
         out = self.conv1(x)
         out = self.bn1(out)
         out = self.relu(out)
-        spx = paddle.split(out, int(out.shape[1]/self.width), 1)
+        spx = paddle.split(out, int(out.shape[1] / self.width), 1)
         for i in range(self.nums):
             if i == 0:
                 sp = spx[i]
             else:
                 sp = sp + spx[i]
             sp = self.convs[i](sp)
             sp = self.relu(self.bns[i](sp))
             if i == 0:
                 out = sp
             else:
                 out = paddle.concat((out, sp), 1)
-
         out = self.conv3(out)
         out = self.bn3(out)
 
         residual = self.shortcut(x)
         out += residual
         out = self.relu(out)
 
@@ -142,33 +141,29 @@
                 nn.Conv2D(in_planes, self.expansion * planes, kernel_size=1, stride=stride),
                 nn.BatchNorm2D(self.expansion * planes))
         self.stride = stride
         self.width = width
         self.scale = scale
 
     def forward(self, x):
-        residual = x
-
         out = self.conv1(x)
         out = self.bn1(out)
         out = self.relu(out)
-        spx = paddle.split(out, int(out.shape[1]/self.width), 1)
+        spx = paddle.split(out, int(out.shape[1] / self.width), 1)
         for i in range(self.nums):
             if i == 0:
                 sp = spx[i]
             else:
                 sp = self.fuse_models[i - 1](sp, spx[i])
-
             sp = self.convs[i](sp)
             sp = self.relu(self.bns[i](sp))
             if i == 0:
                 out = sp
             else:
                 out = paddle.concat((out, sp), 1)
-
         out = self.conv3(out)
         out = self.bn3(out)
 
         residual = self.shortcut(x)
         out += residual
         out = self.relu(out)
 
@@ -193,19 +188,15 @@
         self.in_planes = m_channels
         self.expansion = expansion
         self.feat_dim = input_size
         self.embd_dim = embd_dim
         self.stats_dim = int(input_size / 8) * m_channels * 8
         self.two_emb_layer = two_emb_layer
 
-        self.conv1 = nn.Conv2D(1,
-                               m_channels,
-                               kernel_size=3,
-                               stride=1,
-                               padding=1)
+        self.conv1 = nn.Conv2D(1, m_channels, kernel_size=3, stride=1, padding=1)
         self.bn1 = nn.BatchNorm2D(m_channels)
         self.layer1 = self._make_layer(block, m_channels, num_blocks[0], stride=1,
                                        base_width=base_width, scale=scale)
         self.layer2 = self._make_layer(block, m_channels * 2, num_blocks[1], stride=2,
                                        base_width=base_width, scale=scale)
         self.layer3 = self._make_layer(block_fuse, m_channels * 4, num_blocks[2], stride=2,
                                        base_width=base_width, scale=scale)
@@ -264,9 +255,208 @@
 
         embed_a = self.seg_1(stats)
         if self.two_emb_layer:
             out = F.relu(embed_a)
             out = self.seg_bn_1(out)
             embed_b = self.seg_2(out)
             return embed_b
+        else:
+            return embed_a
+
+
+class BasicBlockERes2NetV2(nn.Layer):
+
+    def __init__(self, expansion, in_planes, planes, stride=1, base_width=26, scale=2):
+        super(BasicBlockERes2NetV2, self).__init__()
+        self.expansion = expansion
+        width = int(math.floor(planes * (base_width / 64.0)))
+        self.conv1 = nn.Conv2D(in_planes, width * scale, kernel_size=1, stride=stride)
+        self.bn1 = nn.BatchNorm2D(width * scale)
+        self.nums = scale
+
+        convs = []
+        bns = []
+        for i in range(self.nums):
+            convs.append(nn.Conv2D(width, width, kernel_size=3, padding=1))
+            bns.append(nn.BatchNorm2D(width))
+        self.convs = nn.LayerList(convs)
+        self.bns = nn.LayerList(bns)
+        self.relu = ReLU(inplace=True)
+
+        self.conv3 = nn.Conv2D(width * scale, planes * self.expansion, kernel_size=1)
+        self.bn3 = nn.BatchNorm2D(planes * self.expansion)
+        self.shortcut = nn.Sequential()
+        if stride != 1 or in_planes != self.expansion * planes:
+            self.shortcut = nn.Sequential(
+                nn.Conv2D(in_planes, self.expansion * planes, kernel_size=1, stride=stride),
+                nn.BatchNorm2D(self.expansion * planes))
+        self.stride = stride
+        self.width = width
+        self.scale = scale
+
+    def forward(self, x):
+        out = self.conv1(x)
+        out = self.bn1(out)
+        out = self.relu(out)
+        spx = paddle.split(out, int(out.shape[1] / self.width), 1)
+        for i in range(self.nums):
+            if i == 0:
+                sp = spx[i]
+            else:
+                sp = sp + spx[i]
+            sp = self.convs[i](sp)
+            sp = self.relu(self.bns[i](sp))
+            if i == 0:
+                out = sp
+            else:
+                out = paddle.concat((out, sp), 1)
+        out = self.conv3(out)
+        out = self.bn3(out)
+
+        residual = self.shortcut(x)
+        out += residual
+        out = self.relu(out)
+
+        return out
+
+
+class BasicBlockERes2NetV2_AFF(nn.Layer):
+
+    def __init__(self, expansion, in_planes, planes, stride=1, base_width=26, scale=2):
+        super(BasicBlockERes2NetV2_AFF, self).__init__()
+        self.expansion = expansion
+        width = int(math.floor(planes * (base_width / 64.0)))
+        self.conv1 = nn.Conv2D(in_planes, width * scale, kernel_size=1, stride=stride)
+        self.bn1 = nn.BatchNorm2D(width * scale)
+        self.nums = scale
+
+        convs = []
+        fuse_models = []
+        bns = []
+        for i in range(self.nums):
+            convs.append(nn.Conv2D(width, width, kernel_size=3, padding=1))
+            bns.append(nn.BatchNorm2D(width))
+        for j in range(self.nums - 1):
+            fuse_models.append(AFF(channels=width, r=4))
+
+        self.convs = nn.LayerList(convs)
+        self.bns = nn.LayerList(bns)
+        self.fuse_models = nn.LayerList(fuse_models)
+        self.relu = ReLU(inplace=True)
+
+        self.conv3 = nn.Conv2D(width * scale, planes * self.expansion, kernel_size=1)
+        self.bn3 = nn.BatchNorm2D(planes * self.expansion)
+        self.shortcut = nn.Sequential()
+        if stride != 1 or in_planes != self.expansion * planes:
+            self.shortcut = nn.Sequential(
+                nn.Conv2D(in_planes, self.expansion * planes, kernel_size=1, stride=stride),
+                nn.BatchNorm2D(self.expansion * planes))
+        self.stride = stride
+        self.width = width
+        self.scale = scale
+
+    def forward(self, x):
+        out = self.conv1(x)
+        out = self.bn1(out)
+        out = self.relu(out)
+        spx = paddle.split(out, int(out.shape[1] / self.width), 1)
+        for i in range(self.nums):
+            if i == 0:
+                sp = spx[i]
+            else:
+                sp = self.fuse_models[i - 1](sp, spx[i])
+            sp = self.convs[i](sp)
+            sp = self.relu(self.bns[i](sp))
+            if i == 0:
+                out = sp
+            else:
+                out = paddle.concat((out, sp), 1)
+        out = self.conv3(out)
+        out = self.bn3(out)
+
+        residual = self.shortcut(x)
+        out += residual
+        out = self.relu(out)
+
+        return out
+
+
+class ERes2NetV2(nn.Layer):
+    def __init__(self,
+                 input_size,
+                 block=BasicBlockERes2NetV2,
+                 block_fuse=BasicBlockERes2NetV2_AFF,
+                 num_blocks=[3, 4, 6, 3],
+                 m_channels=32,
+                 expansion=2,
+                 base_width=26,
+                 scale=2,
+                 embd_dim=192,
+                 pooling_type='TSTP',
+                 two_emb_layer=False):
+        super(ERes2NetV2, self).__init__()
+        self.in_planes = m_channels
+        self.expansion = expansion
+        self.embd_dim = embd_dim
+        self.stats_dim = int(input_size / 8) * m_channels * 8
+        self.two_emb_layer = two_emb_layer
+
+        self.conv1 = nn.Conv2D(1, m_channels, kernel_size=3, stride=1, padding=1)
+        self.bn1 = nn.BatchNorm2D(m_channels)
+        self.layer1 = self._make_layer(block, m_channels, num_blocks[0], stride=1,
+                                       base_width=base_width, scale=scale)
+        self.layer2 = self._make_layer(block, m_channels * 2, num_blocks[1], stride=2,
+                                       base_width=base_width, scale=scale)
+        self.layer3 = self._make_layer(block_fuse, m_channels * 4, num_blocks[2], stride=2,
+                                       base_width=base_width, scale=scale)
+        self.layer4 = self._make_layer(block_fuse, m_channels * 8, num_blocks[3], stride=2,
+                                       base_width=base_width, scale=scale)
+
+        # Downsampling module
+        self.layer3_ds = nn.Conv2D(m_channels * 8, m_channels * 16, kernel_size=3, padding=1, stride=2)
+
+        # Bottom-up fusion module
+        self.fuse34 = AFF(channels=m_channels * 16, r=4)
+
+        self.n_stats = 1 if pooling_type == 'TAP' else 2
+        if pooling_type == "TSTP":
+            self.pooling = TemporalStatsPool()
+        else:
+            raise Exception(f'没有{pooling_type}池化层！')
+
+        self.seg_1 = nn.Linear(self.stats_dim * self.expansion * self.n_stats, embd_dim)
+        if self.two_emb_layer:
+            self.seg_bn_1 = nn.BatchNorm1D(embd_dim)
+            self.seg_2 = nn.Linear(embd_dim, embd_dim)
+        else:
+            self.seg_bn_1 = nn.Identity()
+            self.seg_2 = nn.Identity()
+
+    def _make_layer(self, block, planes, num_blocks, stride, base_width, scale):
+        strides = [stride] + [1] * (num_blocks - 1)
+        layers = []
+        for stride in strides:
+            layers.append(block(self.expansion, self.in_planes, planes, stride, base_width, scale))
+            self.in_planes = planes * self.expansion
+        return nn.Sequential(*layers)
+
+    def forward(self, x):
+        x = x.transpose((0, 2, 1))  # (B,T,F) => (B,F,T)
+
+        x = x.unsqueeze_(1)
+        out = F.relu(self.bn1(self.conv1(x)))
+        out1 = self.layer1(out)
+        out2 = self.layer2(out1)
+        out3 = self.layer3(out2)
+        out4 = self.layer4(out3)
+        out3_ds = self.layer3_ds(out3)
+        fuse_out34 = self.fuse34(out4, out3_ds)
+        stats = self.pooling(fuse_out34)
+
+        embed_a = self.seg_1(stats)
+        if self.two_emb_layer:
+            out = F.relu(embed_a)
+            out = self.seg_bn_1(out)
+            embed_b = self.seg_2(out)
+            return embed_b
         else:
             return embed_a
```

## ppvector/models/pooling.py

```diff
@@ -45,14 +45,15 @@
         x = paddle.concat((mean, var), axis=1)
         x = x.unsqueeze(2)
         return x
 
 
 class SelfAttentivePooling(nn.Layer):
     """SAP"""
+
     def __init__(self, in_dim, bottleneck_dim=128):
         # Use Conv1d with stride == 1 rather than Linear, then we don't need to transpose inputs.
         # attention dim = 128
         super(SelfAttentivePooling, self).__init__()
         self.linear1 = nn.Conv1D(in_dim, bottleneck_dim, kernel_size=1)  # equals W and b in the paper
         self.linear2 = nn.Conv1D(bottleneck_dim, in_dim, kernel_size=1)  # equals V and k in the paper
 
@@ -63,14 +64,15 @@
         mean = paddle.sum(alpha * x, axis=2)
         mean = mean.unsqueeze(2)
         return mean
 
 
 class AttentiveStatisticsPooling(nn.Layer):
     """TSP"""
+
     def __init__(self, channels, attention_channels=128, global_context=True):
         super().__init__()
         self.eps = 1e-12
         self.global_context = global_context
         if global_context:
             self.tdnn = TDNNBlock(channels * 3, attention_channels, 1, 1)
         else:
```

## Comparing `ppvector-1.0.3.dist-info/LICENSE` & `ppvector-1.0.4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `ppvector-1.0.3.dist-info/METADATA` & `ppvector-1.0.4.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: ppvector
-Version: 1.0.3
+Version: 1.0.4
 Summary: Voice Print Recognition toolkit on PaddlePaddle
 Home-page: https://github.com/yeyupiaoling/VoiceprintRecognition_PaddlePaddle
 Download-URL: https://github.com/yeyupiaoling/VoiceprintRecognition_PaddlePaddle.git
 Author: yeyupiaoling
 License: Apache License 2.0
 Keywords: Voice,paddle
 Classifier: Intended Audience :: Developers
@@ -77,45 +77,47 @@
 - CAMPPlus：[CAM++: A Fast and Efficient Network for Speaker Verification Using Context-Aware Masking](https://arxiv.org/abs/2303.00332v3)
 - ERes2Net：[An Enhanced Res2Net with Local and Global Feature Fusion for Speaker Verification](https://arxiv.org/abs/2305.12838v1)
 
 # 模型下载
 
 ### 训练CN-Celeb数据，共有2796个说话人。
 
-|    模型     | Params(M) | 预处理方法 |                数据集                 | train speakers | threshold |   EER   | MinDCF  |   模型下载   |
-|:---------:|:---------:|:-----:|:----------------------------------:|:--------------:|:---------:|:-------:|:-------:|:--------:|
-|   CAM++   |    6.8    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.25    | 0.09485 | 0.56214 | 加入知识星球获取 |
-| ERes2Net  |    6.6    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.22    | 0.09637 | 0.52627 | 加入知识星球获取 |
-| ResNetSE  |    7.8    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.19    | 0.10222 | 0.57981 | 加入知识星球获取 |
-| EcapaTdnn |    6.1    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.25    | 0.10465 | 0.58521 | 加入知识星球获取 |
-|   TDNN    |    2.6    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.23    | 0.11804 | 0.61070 | 加入知识星球获取 |
-|  Res2Net  |    5.0    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.18    | 0.14126 | 0.68511 | 加入知识星球获取 |
-|   CAM++   |    6.8    | Fbank |               更大数据集                |      2W+       |   0.34    | 0.07884 | 0.52738 | 加入知识星球获取 |
-|   CAM++   |    6.8    | Flank |               其他数据集                |      20W       |   0.29    | 0.04768 | 0.31429 | 加入知识星球获取 |
-| ERes2Net  |   55.1    | Fbank |               其他数据集                |      20W       |   0.36    | 0.02939 | 0.18355 | 加入知识星球获取 |
+|     模型     | Params(M) | 预处理方法 |                数据集                 | train speakers | threshold |   EER   | MinDCF  |   模型下载   |
+|:----------:|:---------:|:-----:|:----------------------------------:|:--------------:|:---------:|:-------:|:-------:|:--------:|
+|   CAM++    |    6.8    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.25    | 0.09485 | 0.56214 | 加入知识星球获取 |
+|  ERes2Net  |    6.6    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.22    | 0.09637 | 0.52627 | 加入知识星球获取 |
+|  ResNetSE  |    7.8    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.19    | 0.10222 | 0.57981 | 加入知识星球获取 |
+| EcapaTdnn  |    6.1    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.25    | 0.10465 | 0.58521 | 加入知识星球获取 |
+|    TDNN    |    2.6    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.23    | 0.11804 | 0.61070 | 加入知识星球获取 |
+|  Res2Net   |    5.0    | Fbank | [CN-Celeb](http://openslr.org/82/) |      2796      |   0.18    | 0.14126 | 0.68511 | 加入知识星球获取 |
+|   CAM++    |    6.8    | Fbank |               更大数据集                |      2W+       |   0.34    | 0.07884 | 0.52738 | 加入知识星球获取 |
+|   CAM++    |    6.8    | Flank |               其他数据集                |      20W       |   0.29    | 0.04768 | 0.31429 | 加入知识星球获取 |
+| ERes2NetV2 |   56.2    | Fbank |               其他数据集                |      20W+      |   0.36    | 0.03847 | 0.24318 | 加入知识星球获取 |
+|  ERes2Net  |   55.1    | Fbank |               其他数据集                |      20W       |   0.36    | 0.02939 | 0.18355 | 加入知识星球获取 |
 
 说明：
 1. 评估的测试集为[CN-Celeb的测试集](https://aistudio.baidu.com/aistudio/datasetdetail/233361)，包含196个说话人。
 2. 使用语速增强分类大小翻三倍`speed_perturb_3_class: True`。
 3. 参数数量不包含了分类器的参数数量。
 
 
 ### 训练VoxCeleb1&2数据，共有7205个说话人。
 
-|    模型     | Params(M) | 预处理方法 |     数据集     | train speakers | threshold |   EER   | MinDCF  |   模型下载   |
-|:---------:|:---------:|:-----:|:-----------:|:--------------:|:---------:|:-------:|:-------:|:--------:|
-|   CAM++   |    6.8    | Fbank | VoxCeleb1&2 |      7205      |   0.27    | 0.03350 | 0.25726 | 加入知识星球获取 |
-| ERes2Net  |    6.6    | Fbank | VoxCeleb1&2 |      7205      |   0.21    | 0.03997 | 0.30614 | 加入知识星球获取 |
-| ResNetSE  |    7.8    | Fbank | VoxCeleb1&2 |      7205      |   0.21    | 0.03758 | 0.27625 | 加入知识星球获取 |
-| EcapaTdnn |    6.1    | Fbank | VoxCeleb1&2 |      7205      |   0.27    | 0.02852 | 0.19432 | 加入知识星球获取 |
-|   TDNN    |    2.6    | Fbank | VoxCeleb1&2 |      7205      |   0.25    | 0.03541 | 0.28130 | 加入知识星球获取 |
-|  Res2Net  |    5.0    | Fbank | VoxCeleb1&2 |      7205      |   0.21    | 0.04749 | 0.44950 | 加入知识星球获取 |
-|   CAM++   |    6.8    | Fbank |    更大数据集    |      2W+       |   0.28    | 0.03192 | 0.22032 | 加入知识星球获取 |
-|   CAM++   |    6.8    | Fbank |    其他数据集    |      20W+      |   0.49    | 0.10331 | 0.71206 | 加入知识星球获取 |
-| ERes2Net  |   55.1    | Fbank |    其他数据集    |      20W+      |   0.53    | 0.08903 | 0.62131 | 加入知识星球获取 |
+|     模型     | Params(M) | 预处理方法 |     数据集     | train speakers | threshold |   EER   | MinDCF  |   模型下载   |
+|:----------:|:---------:|:-----:|:-----------:|:--------------:|:---------:|:-------:|:-------:|:--------:|
+|   CAM++    |    6.8    | Fbank | VoxCeleb1&2 |      7205      |   0.27    | 0.03350 | 0.25726 | 加入知识星球获取 |
+|  ERes2Net  |    6.6    | Fbank | VoxCeleb1&2 |      7205      |   0.21    | 0.03997 | 0.30614 | 加入知识星球获取 |
+|  ResNetSE  |    7.8    | Fbank | VoxCeleb1&2 |      7205      |   0.21    | 0.03758 | 0.27625 | 加入知识星球获取 |
+| EcapaTdnn  |    6.1    | Fbank | VoxCeleb1&2 |      7205      |   0.27    | 0.02852 | 0.19432 | 加入知识星球获取 |
+|    TDNN    |    2.6    | Fbank | VoxCeleb1&2 |      7205      |   0.25    | 0.03541 | 0.28130 | 加入知识星球获取 |
+|  Res2Net   |    5.0    | Fbank | VoxCeleb1&2 |      7205      |   0.21    | 0.04749 | 0.44950 | 加入知识星球获取 |
+|   CAM++    |    6.8    | Fbank |    更大数据集    |      2W+       |   0.28    | 0.03192 | 0.22032 | 加入知识星球获取 |
+|   CAM++    |    6.8    | Fbank |    其他数据集    |      20W+      |   0.49    | 0.10331 | 0.71206 | 加入知识星球获取 |
+| ERes2NetV2 |   56.2    | Fbank |    其他数据集    |      20W+      |   0.52    | 0.08649 | 0.64201 | 加入知识星球获取 |
+|  ERes2Net  |   55.1    | Fbank |    其他数据集    |      20W+      |   0.53    | 0.08903 | 0.62131 | 加入知识星球获取 |
 
 说明：
 
 1. 评估的测试集为[VoxCeleb1&2的测试集](https://aistudio.baidu.com/aistudio/datasetdetail/255977)，包含158个说话人。
 2. 使用语速增强分类大小翻三倍`speed_perturb_3_class: True`。
 3. 参数数量不包含了分类器的参数数量。
```

## Comparing `ppvector-1.0.3.dist-info/RECORD` & `ppvector-1.0.4.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,33 +1,33 @@
-ppvector/__init__.py,sha256=1Nqnj-dBG8NZOTjUbPp9NWTy0ddKc5o7d-vkgz53aw0,134
-ppvector/predict.py,sha256=yELfuPb6_bWbIsjbYdy_mYbVh9LoWNR5yzZBsIEHSio,17483
-ppvector/trainer.py,sha256=UWpENmFackuipoxsjGTb46UbhHSSb1cKInhi4CXFDB0,36494
+ppvector/__init__.py,sha256=1zetSbdKZkGIeDAhU5LjUXdAVng_ORH7ucvFUC60Ios,148
+ppvector/predict.py,sha256=qJU-Gf54zz7BJgbUmRmPvGp07P4eqXLrIo6Rf1YlGMA,17667
+ppvector/trainer.py,sha256=jqnSpqYV2WuG_d2gO2Nf3UkxfVTFEiLIsaOFx0Jo2p8,37307
 ppvector/data_utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ppvector/data_utils/audio.py,sha256=If9HGHdfZeNjQgERNl8TTY8MFbkkWF0NKXq_RA5uTjs,22221
 ppvector/data_utils/collate_fn.py,sha256=uzm-U3avFXzjJXbM6u5CfUJUr4WlIYcaz7WDmgetRys,947
 ppvector/data_utils/featurizer.py,sha256=wWgZoR0ZdTZ0Ux0byI4qT2Go86njSxFskQFz8xtipf0,3919
 ppvector/data_utils/reader.py,sha256=oCfYgQVVA1YHfWu_HjV4PDd64RNIAEhhbrOenNrVCbs,7419
 ppvector/data_utils/spec_aug.py,sha256=Qw32xZTw1f8Fk3Kw9aQt_5IKiH8k1giXbCX3XUzU1xw,1581
 ppvector/data_utils/utils.py,sha256=wripWTTPcEOgskVli8eTyHROs8wok8CItFd8uYpIBcU,4713
 ppvector/metric/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ppvector/metric/metrics.py,sha256=BuQcf0E_6JUwbdFYKvzpb3rCAssizJjk_JvrQmLlfkA,1208
 ppvector/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ppvector/models/campplus.py,sha256=Xfq1O8zdf9sDjMsoQ-1E2rpScoMlaJjfErBxCyBytgM,12745
 ppvector/models/ecapa_tdnn.py,sha256=QNfiMvCjlvFC2msxsYdzQZOUt-n4X4KwZ5wIHA3euO4,10987
-ppvector/models/eres2net.py,sha256=5y39Ol5FOWZvKW803CGa5ZFux7GfkzfFzDsS3KwsAfc,10135
+ppvector/models/eres2net.py,sha256=J9HqoF4FRzLGaZgG1VDAOdXvfNHsN_jG77HdpArmWM4,17612
 ppvector/models/fc.py,sha256=dtMca714xkcaP_399V-1pzfBGUeR1cXpkQ3bhJj5jx4,3731
 ppvector/models/loss.py,sha256=6WSKIpRiUFktzkClZdvTae2GYxZKzS2LmtINgWX6unE,9521
-ppvector/models/pooling.py,sha256=WVJILqRl9YyghxsTUJR9fTwRA3XCr69Kns_08FPvCGA,5279
+ppvector/models/pooling.py,sha256=m9gl0_fMvein6ell8I5Wxgoop8SbynmRD_T-tCn4ZsE,5283
 ppvector/models/res2net.py,sha256=f2-cv1VQi6KkF8NETt2-BsLvVIlvjM2whUiBaCCeZtQ,6843
 ppvector/models/resnet_se.py,sha256=dmet6cJZvE3DGmfnlpT95exy-9cP2eeWiK-6AmtCH_Q,5662
 ppvector/models/tdnn.py,sha256=t_thrn6_UxV9xn4Hn6I3-l-V9_YxP8vH5qm7uvRtNiI,3459
 ppvector/models/utils.py,sha256=WFaGb66sSLalS-2yr9VIOnICrLjR8rGmiggGaWnZV_Y,5049
 ppvector/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ppvector/utils/logger.py,sha256=-ssorx8FlHA_wrd2Eq6f4HkOqaOG2YseBGvYAo8NXN8,2839
 ppvector/utils/record.py,sha256=S2sGoLPJrdRsrG7_ojNt4kwL05VNrOxnmnMOwNOZ9-0,1385
 ppvector/utils/scheduler.py,sha256=IZ1kU6S86hfnuZLfkepflStogDyYvRPEDMP4P_mwGvs,3399
 ppvector/utils/utils.py,sha256=zzBjiCYwNwxYGMfZyo_wubYp5MTmN3YRuFMKXZ65S7c,2790
-ppvector-1.0.3.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
-ppvector-1.0.3.dist-info/METADATA,sha256=T0dM1Hfh19MRd1N52CUZDJsO1ntDFWaelz66FK3VU9Q,34237
-ppvector-1.0.3.dist-info/WHEEL,sha256=yQN5g4mg4AybRjkgi-9yy4iQEFibGQmlz78Pik5Or-A,92
-ppvector-1.0.3.dist-info/top_level.txt,sha256=NywKjkr9phu2LhphLKQRNvdJUG8iJGaZQbe_HC0PhcQ,9
-ppvector-1.0.3.dist-info/RECORD,,
+ppvector-1.0.4.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
+ppvector-1.0.4.dist-info/METADATA,sha256=CKgtms3ec_xGpFPvQq4Y1jCL8lXQi2FFDWOKUsqTALU,34554
+ppvector-1.0.4.dist-info/WHEEL,sha256=yQN5g4mg4AybRjkgi-9yy4iQEFibGQmlz78Pik5Or-A,92
+ppvector-1.0.4.dist-info/top_level.txt,sha256=NywKjkr9phu2LhphLKQRNvdJUG8iJGaZQbe_HC0PhcQ,9
+ppvector-1.0.4.dist-info/RECORD,,
```

